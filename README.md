
# ğŸ§  Bengali Text Summarizer using Transformer + FastAPI

A powerful Bengali text summarization web app built with a custom Transformer model and served using FastAPI. Input Bengali text and receive a concise, generated summary powered by a deep learning model.

---

## ğŸš€ Features

- âœï¸ **Summarize Bengali Text**: Generate concise summaries for long-form Bengali input.
- âš™ï¸ **Transformer-based Model**: Custom-built encoder-decoder architecture with multi-head attention.
- ğŸ§  **Custom-trained SentencePiece Tokenizer**: Efficient subword tokenization for Bengali.
- ğŸŒ **FastAPI Backend**: Fast, asynchronous API with a responsive web interface.
- ğŸ’¾ **Model Checkpoint Loader**: Automatically loads the latest trained weights.
- âœ… **Health Check Route**: Useful for deployment uptime checks.

---

## ğŸ“¸ Demo

> Coming soon! 

---

## ğŸ› ï¸ Tech Stack

- **Python 3.x**
- **TensorFlow 2.x** - Deep learning framework
- **SentencePiece** - Tokenizer for Bengali text
- **FastAPI** - Web framework for serving the app
- **Jinja2** - HTML template rendering
- **HTML/CSS/JavaScript/Bootstrap** - Frontend for user input and display
- **[Render](https://render.com/)** - For Deployment

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ main.py                  # FastAPI app
â”œâ”€â”€ transformer.py           # Model architecture and summarization logic
â”œâ”€â”€ tokenizer/               # SentencePiece model
â”‚   â””â”€â”€ bengali_spm.model
â”œâ”€â”€ weights/                 # Trained model checkpoints
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html           # Frontend page
â”œâ”€â”€ static/                  # CSS, JS files (optional)
â””â”€â”€ README.md                
```

---

## âš¡ Quick Start

### ğŸ“ 1. Clone the repository
```b
git clone https://github.com/SoumyaMajhi/Bengali-Text-Summarization.git
cd Bengali-Text-Summarization
```

### ğŸ§ª 2. Create and activate a virtual environment (Optional)
```
python -m venv venv
```
### â–¶ï¸ Activate the environment:
On Windows:
```
venv\Scripts\activate
```
On macOS/Linux:
```
source venv/bin/activate
```

### ğŸ”§ 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### ğŸš¦ 4. Run Locally

```bash
uvicorn main:app --reload
```

ğŸ”— Then open your browser at: [http://127.0.0.1:8000](http://127.0.0.1:8000)

---

## ğŸ” API Reference

### `GET /`
Returns the web interface.

### `POST /summarize`

**Input JSON:**
```json
{
  "original_text": "à¦†à¦ªà¦¨à¦¾à¦° à¦‡à¦¨à¦ªà§à¦Ÿ à¦¬à¦¾à¦‚à¦²à¦¾ à¦Ÿà§‡à¦•à§à¦¸à¦Ÿ à¦à¦–à¦¾à¦¨à§‡"
}
```

**Response:**
```json
{
  "summary": "à¦¸à¦¾à¦°à¦¾à¦‚à¦¶"
}
```

### `GET /health`
Check if the server is running.

---

## ğŸ“š Model Details

- Transformer with:
  - `NUM_LAYERS = 4`
  - `D_MODEL = 128`
  - `NUM_HEADS = 8`
  - `DFF = 512`
  - `TEXT_LENGTH = 512`
  - `SUMMARY_LENGTH = 16`
  - `VOCAB_SIZE = 10000`

- Trained on two custom Bengali datasets scraped from [ProthomAlo](https://www.kaggle.com/datasets/samym4/prothom-alo-cleaned-dataset) & [Eisamay](https://www.kaggle.com/datasets/samym4/eisamay-bengali-news-dataset)
- Custom Tokenization on our datasets with SentencePiece (`.model` included in `tokenizer/`)

---

## ğŸ”§ For Render Deployment
Set:
- `Build Command` as `pip install -r requirements.txt`
- `Start Command` as `uvicorn main:app --host 0.0.0.0 --port 8000`

Set the following environment variables:
- `PYTHON_VERSION = 3.10.13` (for Tensorflow compatibility)
- `HOST = 0.0.0.0`
- `PORT = 8000`





## ğŸ§  Future Work

- Add a frontend summarization history
- Upload and summarize `.txt` or `.pdf` files
- Host on Hugging Face
- Model improvement (more layers or pretrained embeddings)
- Dockerized backend

---

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, open an issue first to discuss what youâ€™d like to change or improve.
